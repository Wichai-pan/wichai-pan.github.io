---
layout: post
title: CV Lecture 1
author: wichai
date: 2025-01-13 17:00 +0000
categories:
  - Study
  - Master
tags:
  - DU
  - CV
mermaid: true
math: true
pin: false
---


paolo

4 weeks

5个话题 ML 

# Introduction



## What is CV

- enable machines to see
- Seeing implies more than taking a photograph or a video clip of the external world



- Light passes through the cornea(the clear front layer of the eye)The cornea bends light to help the eye focus
- Some of this light enters the eye through an opening called the pupil
- The iris(the coloured part of the eye) controls how much light the pupil lets in
- Next, light passes through the lens(a clear inner part of the eye). The lens works together with the cornea to focus light correctly on the retina.
- When light hits the retina(a light-sensitive layer of tissue at the back of the eye), special cells called photoreceptors turn the light into electrical signal.





## Image Processing versus Computer Vision (the difference)

- **Image Processing**: generally, the enhancement, restoration, representation or transformation of visual data to aid in viewing and interpretation by humans.
- **Computer Vision**: automatic interpretation of visual data using computers(without humanintervention)



## Typical computer Vision Processing Pipeline

![image-20250116114635632](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/image-20250116114635632.png)



## What's an image

•We mentioned the three colour channels in an earlier slide

•A colour image usually contains targets (objects, animals and/or people) that have distinctive characteristics, in computer vision called features

•Features could be delimiting edges, or points of interest

•Features could also be the textures of a fabric or skin or other making an object different from others

•Our first task is to find ways to implement algorithms that can detect these distinctive features to be able and identify targets and then describe them 



## Challenges in computer vision

- Ambiguity
  - Many different 3D scenes could have given rise to a particular 2D picture
- Complexity of a scence
  - Illumination
  - Object pose Clutter
  - Occlusions
  - Intra-class appearance
  - Viewpoint
- Scale of targets
- Dynamics
- Occlusion and clutter
- Intra-class variations



## The importance of edges in and image

- use of outlines or edges of objects for:
  - recognition
  - perception of distance and orientation
- One of the most important aspects of human vision
  - visual cortex feature detectors that are tuned to the edges and segments of various widths and orientations



Edge based Segmentation

- Segmenting scene objects by discontinuity
  - image features where there is an abrupt change in intensity
  - indicating the end of one region and the beginning of another

How can we implement an edge detector

- Edge detection = differential operators to detect gradients of the gray or colour levels in the image
- If the image is I(x, y) then the basic idea is to compute

$$

$$



## Edge Detection Techniques

**Image gradient**

- Let the image be thus with partial derivatives we have:

$$

$$

and
$$

$$

- An image is digital object with discrete elements (picture elements, also called pixels)
- We can replace the partial derivatives with differences
  - 1
- 
