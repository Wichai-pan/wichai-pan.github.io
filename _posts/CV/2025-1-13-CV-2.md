---
layout: post
title: CV Lecture 2
author: wichai
date: 2025-01-13 17:00 +0000
categories:
  - Study
  - Master
tags:
  - DU
  - CV
mermaid: true
math: true
pin: false
---

# Lecture 2

**Colour and Colour Images**

- A colour image has three components: red, green and blue
- The components are usually called channels

**Electromagnetic radiation**

All electromagnetic radiation is light, but we can only see a small portion of this radiationæ‰€æœ‰ç”µç£è¾å°„éƒ½æ˜¯å…‰ï¼Œä½†æˆ‘ä»¬åªèƒ½çœ‹åˆ°å…¶ä¸­çš„ä¸€å°éƒ¨åˆ†

the portion we call visible lightæˆ‘ä»¬ç§°ä¹‹ä¸ºå¯è§å…‰çš„éƒ¨åˆ†

Cone-shaped cells in our eyes act as receivers tuned to the wavelengths in thisnarrow band of the spectrumæˆ‘ä»¬çœ¼ä¸­çš„é”¥å½¢ç»†èƒå……å½“æ¥æ”¶å™¨ï¼Œå¯è°ƒè°åˆ°å…‰è°±ä¸­è¿™ä¸ªçª„å¸¦å†…çš„æ³¢é•¿

Other portions of the spectrum have wavelengths too large or too small andenergetic for the biological limitations of our perception.å…‰è°±çš„å…¶ä»–éƒ¨åˆ†çš„æ³¢é•¿å¯¹äºæˆ‘ä»¬æ„ŸçŸ¥çš„ç”Ÿç‰©å­¦é™åˆ¶æ¥è¯´å¤ªå¤§æˆ–å¤ªå°ä¸”èƒ½é‡è¿‡å¤§ã€‚
![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119164015.png)

## K-means Clustering for Colour Quantization
- Observations are partitioned in K clusters, ergo the name of the method
	- è§‚æµ‹ç»“æœè¢«åˆ’åˆ†ä¸º K ä¸ªç°‡ï¼Œå› æ­¤å¾—åè¯¥æ–¹æ³•
- Each new observation is tagged as member of a cluster, using Euclidean distance
	- ä½¿ç”¨æ¬§å‡ é‡Œå¾—è·ç¦»å°†æ¯ä¸ªæ–°è§‚æµ‹ç»“æœæ ‡è®°ä¸ºç°‡çš„æˆå‘˜
- Each time a cluster changes size, its centre is recalculated
	- æ¯æ¬¡ç°‡å¤§å°å‘ç”Ÿå˜åŒ–æ—¶ï¼Œéƒ½ä¼šé‡æ–°è®¡ç®—å…¶ä¸­å¿ƒ
- If we want to use K-means for colour quantization, we use colours are clusters
	- å¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨ K å‡å€¼è¿›è¡Œé¢œè‰²é‡åŒ–ï¼Œæˆ‘ä»¬ä¼šå°†é¢œè‰²ç”¨ä½œç°‡
- Algorithm termination follows the usual practice: either number of max iterations reachedor centres do not change much
	- ç®—æ³•ç»ˆæ­¢éµå¾ªé€šå¸¸çš„åšæ³•ï¼šè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°æˆ–ä¸­å¿ƒå˜åŒ–ä¸ å¤§
![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119164128.png)

## Probability Density Function (PDF)
- The histogram model is a crude version of a probability density function
- A probability density function is a measurement of how often an observation falls within a specified range
	- In our case the bins in the UV colour space
- Once the accumulator is in place, it must be normalised
	- This means all bins are summed together and then each bin divided by the sum
- Then each bin will represent of the probability of a given colour

## Better ways to find edges
Image gradient
- The gradient of an image:

$$
  \nabla f=\left[\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}\right]
$$

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119164643.png)

The gradient vector points in the direction of most rapid increase in intensity
The gradient direction is given by $\theta=\tan^{-1}\left(\frac{\partial f}{\partial y}/\frac{\partial f}{\partial x}\right)$
	- how does this relate to the direction of the edge?
The edge strength is given by the gradient magnitude

$$
\|\nabla f\|=\sqrt{\left(\frac{\partial f}{\partial x}\right)^2+\left(\frac{\partial f}{\partial y}\right)^2}
$$

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165149.png)

## Effect of noise
- Our edge operators implement finite differences, local operations
	- æˆ‘ä»¬çš„è¾¹ç¼˜è¿ç®—ç¬¦å®ç°æœ‰é™å·®åˆ†ã€å±€éƒ¨è¿ç®—
- If we add noise to an image, we have neighbouring pixels with very different values
	- å¦‚æœæˆ‘ä»¬å‘å›¾åƒæ·»åŠ å™ªå£°ï¼Œåˆ™ç›¸é‚»åƒç´ çš„å€¼ä¼šæœ‰å¾ˆå¤§å·®å¼‚
- The more they differ the stronger is the filter response
	- å®ƒä»¬çš„å·®å¼‚è¶Šå¤§ï¼Œæ»¤æ³¢å™¨å“åº”è¶Šå¼º
- Therefore, we must smooth an image before running an edge filter
	- å› æ­¤ï¼Œæˆ‘ä»¬å¿…é¡»åœ¨è¿è¡Œè¾¹ç¼˜æ»¤æ³¢å™¨ä¹‹å‰å¹³æ»‘å›¾åƒ
## Smoothing filters
- We have learnt the Gaussian operator
- You can also use the mean, we have come across as well, and the median
- The median is calculated by a
	- first sorting all the pixel values from the surrounding neighbourhood into numericalorder and
	- then replacing the pixel being considered with the middle pixel value

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165309.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165314.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165322.png)

## Edge detection steps
Usually there are three steps in the edge detection process
1. Noise reduction
- Suppress as much noise as possible without removing edges.
2. Edge enhancement
- Highlight edges and weaken elsewhere (high pass filter)
3. Edge localisation
- Look at possible edges (maxima of output from previous filter) and eliminate spuriousedges (often noise related)

## Problems with Sobel filter

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165416.png)

## **Advanced Edge Detection**

**Canny edge detection**

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119165430.png)

Gaussian smoothing
- The result of applying Gaussian Filter on the image is blurring and reducing the noise from the image
- The Gaussian function formula is used for generating a Gaussian filter mask
- In this formula, ğœ (sigma) controls the width of the filter which is impact averaging overthe neighbourhood
	- ğœ should be greater than 0

Canny : Gaussian Image Smoothing
- Smooth image with a 2D Gaussian
- **Method**: convolve with a mask that approximates the 2D Gaussian kernel
- **Result**: pixels averaged over local neighbourhood with preference towards the centre
	- smooths noise without too much blurring of edges

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119190933.png)

**Non-maximum suppression**
- The image magnitude produced results with thick edges
- Ideally, the final image should have thin edges
- The principle is simple
	- the algorithm goes through all the points on the gradient intensity matrix and findsthe pixels with the maximum value along the edge directions
- Each pixel has 2 main criteria
	- æ¯ä¸ªåƒç´ æœ‰ 2 ä¸ªä¸»è¦æ ‡å‡†
	- edge direction in radians, and
		- è¾¹ç¼˜æ–¹å‘ï¼ˆå¼§åº¦ï¼‰å’Œ
	- pixel intensity (between 0â€“255)
		- åƒç´ å¼ºåº¦ï¼ˆ0-255 ä¹‹é—´ï¼‰
- Based on these inputs the non-max-suppression steps
	- æ ¹æ®è¿™äº›è¾“å…¥æ‰§è¡Œéæœ€å¤§æŠ‘åˆ¶æ­¥éª¤
- Create a matrix initialized to 0 of the same size of the original gradient intensitymatrix
	- åˆ›å»ºä¸€ä¸ªåˆå§‹åŒ–ä¸º 0 çš„çŸ©é˜µï¼Œå…¶å¤§å°ä¸åŸå§‹æ¢¯åº¦å¼ºåº¦çŸ©é˜µç›¸åŒ
- Identify the edge direction based on the angle value from the angle matrix
	- æ ¹æ®è§’åº¦çŸ©é˜µçš„è§’åº¦å€¼è¯†åˆ«è¾¹ç¼˜æ–¹å‘
- Check if the pixel in the same direction has a higher intensity than the pixel that iscurrently processed
	- æ£€æŸ¥åŒä¸€æ–¹å‘ä¸Šçš„åƒç´ æ˜¯å¦æ¯”å½“å‰å¤„ç†çš„åƒç´ å…·æœ‰æ›´é«˜çš„å¼ºåº¦
- Return the image processed with the non-max suppression algorithm
	- è¿”å›ä½¿ç”¨éæœ€å¤§æŠ‘åˆ¶ç®—æ³•å¤„ç†çš„å›¾åƒ
![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191207.png)

- Non maximum suppression can be achieved by interpolating the pixels for greateraccuracy

$$
  r=\alpha b+(1-\alpha)a
$$

- Non maximum suppression does not provide perfect results
- A low and a high threshold can be used to determine weak and strong edges
- Edge tracking must be implemented as follows
	- Weak edges that are connected to strong edges will be actual/real edges
	- Weak edges that are not connected to strong edges will be removed

**Double thresholding**
- It aims at identifying 3 kinds of pixels: strong, weak, and non-relevant
	- å®ƒæ—¨åœ¨è¯†åˆ« 3 ç§åƒç´ ï¼šå¼ºåƒç´ ã€å¼±åƒç´ å’Œä¸ç›¸å…³åƒç´ 
- Strong pixels are pixels that have an intensity so high that we are sure they contribute to the final edge
	- å¼ºåƒç´ æ˜¯å¼ºåº¦éå¸¸é«˜çš„åƒç´ ï¼Œæˆ‘ä»¬ç¡®ä¿¡å®ƒä»¬å¯¹æœ€ç»ˆè¾¹ç¼˜æœ‰è´¡çŒ®
- Weak pixels are pixels that have an intensity value that is not enough to be considered asstrong ones, but yet not small enough to be considered as non-relevant for the edgedetection.
	- å¼±åƒç´ æ˜¯å¼ºåº¦å€¼ä¸è¶³ä»¥è¢«è§†ä¸ºå¼ºåƒç´ ï¼Œä½†åˆä¸è‡³äºå°åˆ°è¢«è®¤ä¸ºä¸è¾¹ç¼˜æ£€æµ‹ä¸ç›¸å…³çš„åƒç´ ã€‚
- Other pixels are considered as non-relevant for the edge.
	- å…¶ä»–åƒç´ è¢«è®¤ä¸ºä¸è¾¹ç¼˜ä¸ç›¸å…³ã€‚
- High threshold is used to identify the strong pixels (intensity higher than the highthreshold)
	- é«˜é˜ˆå€¼ç”¨äºè¯†åˆ«å¼ºåƒç´ ï¼ˆå¼ºåº¦é«˜äºé«˜é˜ˆå€¼ï¼‰
- Low threshold is used to identify the non-relevant pixels (intensity lower than the lowthreshold)
- All pixels having intensity between both thresholds are flagged as weak and the Hysteresismechanism (next step) will help us identify the ones that could be considered as strongand the ones that are considered as non-relevant.
	- æ‰€æœ‰å¼ºåº¦ä»‹äºä¸¤ä¸ªé˜ˆå€¼ä¹‹é—´çš„åƒç´ å‡è¢«æ ‡è®°ä¸ºå¼±åƒç´ ï¼Œæ»åæœºåˆ¶ï¼ˆä¸‹ä¸€æ­¥ï¼‰å°†å¸®åŠ©æˆ‘ä»¬è¯†åˆ«å¯è§†ä¸ºå¼ºåƒç´ å’Œè¢«è§†ä¸ºä¸ç›¸å…³çš„åƒç´ ã€‚
  
![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191349.png)

**Edge tracking by Hysteresis**
- Based on the threshold results
	- æ ¹æ®é˜ˆå€¼ç»“æœ
- The hysteresis consists of transforming weak pixels into strong ones, if and only if at leastone of the pixels around the one being processed is a strong one
	- æ»ååŒ…æ‹¬å°†å¼±åƒç´ è½¬æ¢ä¸ºå¼ºåƒç´ ï¼Œå½“ä¸”ä»…å½“è¢«å¤„ç†çš„åƒç´ å‘¨å›´è‡³å°‘æœ‰ä¸€ä¸ªåƒç´ æ˜¯å¼ºåƒç´ æ—¶

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191421.png)

## Feature Descriptors
**Histogram of Oriented Gradients (HOG)**
- HOG, or Histogram of Oriented Gradients, is a feature descriptor that is often used toextract features from image data
	- HOGï¼Œå³æ–¹å‘æ¢¯åº¦ç›´æ–¹å›¾ï¼Œæ˜¯ä¸€ç§ç‰¹å¾æè¿°ç¬¦ï¼Œé€šå¸¸ç”¨äºä»å›¾åƒæ•°æ®ä¸­æå–ç‰¹å¾
- HOG is used for object detection
	- HOG ç”¨äºç‰©ä½“æ£€æµ‹
- The HOG descriptor focuses on the structure or the shape of an object
	- HOG æè¿°ç¬¦ä¾§é‡äºç‰©ä½“çš„ç»“æ„æˆ–å½¢çŠ¶
- Please refer to the article by Dalal - https://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf

**Pre-processing for HOG**
- We need to preprocess the image and scale it down to the width to height ratio to 1:2
	- æˆ‘ä»¬éœ€è¦å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶å°†å…¶å®½åº¦ä¸é«˜åº¦çš„æ¯”ä¾‹ç¼©å°åˆ° 1:2
- The image size should preferably be 64 x 128
	- å›¾åƒå¤§å°æœ€å¥½æ˜¯ 64 x 128
- This is because we will be dividing the image into 8 and 16 patches to extract thefeatures
	- è¿™æ˜¯å› ä¸ºæˆ‘ä»¬å°†æŠŠå›¾åƒåˆ†æˆ 8 å’Œ 16 ä¸ªå—æ¥æå–ç‰¹å¾
- With the specified size (64 x 128) will make all calculations simpler
	- ä½¿ç”¨æŒ‡å®šçš„å°ºå¯¸ï¼ˆ64 x 128ï¼‰å°†ä½¿æ‰€æœ‰è®¡ç®—æ›´ç®€å•

**Calculating the gradients and their histogram**
- For every pixel, we calculate the gradient magnitude and orientation
	- å¯¹äºæ¯ä¸ªåƒç´ ï¼Œæˆ‘ä»¬è®¡ç®—æ¢¯åº¦å¹…åº¦å’Œæ–¹å‘
- Check a previous slide on how this can be done
	- æŸ¥çœ‹ä¸Šä¸€å¼ å¹»ç¯ç‰‡äº†è§£å¦‚ä½•æ‰§è¡Œæ­¤æ“ä½œ
- We then create a histogram of local orientations
	- ç„¶åæˆ‘ä»¬åˆ›å»ºå±€éƒ¨æ–¹å‘çš„ç›´æ–¹å›¾
- Pixel 85â€™s gradient has orientation 36, this contributes to that bin
	- åƒç´  85 çš„æ¢¯åº¦å…·æœ‰æ–¹å‘ 36ï¼Œè¿™æœ‰åŠ©äºè¯¥ç®±ä½“

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191626.png)

**How does HOG work**
- Each image is divided in regular cells, say 8x8 pixels
	- æ¯å¹…å›¾åƒè¢«åˆ’åˆ†ä¸ºè§„åˆ™çš„å•å…ƒï¼Œä¾‹å¦‚ 8x8 åƒç´ 
- For each cell a local 1D histogram of gradient directions or edge orientations is accumulated
	- å¯¹äºæ¯ä¸ªå•å…ƒï¼Œéƒ½ä¼šç´¯ç§¯æ¢¯åº¦æ–¹å‘æˆ–è¾¹ç¼˜æ–¹å‘çš„å±€éƒ¨ 1D ç›´æ–¹å›¾
- The combined histogram entries represent the image, or part of it
	- ç»„åˆçš„ç›´æ–¹å›¾æ¡ç›®ä»£è¡¨å›¾åƒæˆ–å›¾åƒçš„ä¸€éƒ¨åˆ†
- Usually, we want to seek invariance to illumination
	- é€šå¸¸ï¼Œæˆ‘ä»¬å¸Œæœ›å¯»æ±‚å¯¹å…‰ç…§çš„ä¸å˜æ€§
- We achieve this by accumulating a measure of local histograms â€œenergyâ€ over larger spatial regions (â€œblocksâ€) and using the result to normalize all the cells in the block
	- æˆ‘ä»¬é€šè¿‡åœ¨è¾ƒå¤§çš„ç©ºé—´åŒºåŸŸï¼ˆâ€œå—â€ï¼‰ä¸Šç´¯ç§¯å±€éƒ¨ç›´æ–¹å›¾â€œèƒ½é‡â€çš„åº¦é‡å¹¶ä½¿ç”¨ç»“æœå¯¹å—ä¸­çš„æ‰€æœ‰å•å…ƒè¿›è¡Œå½’ä¸€åŒ–æ¥å®ç°è¿™ä¸€ç‚¹

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191802.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191841.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191848.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191854.png)

![](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191854.png)

![image.png](https://wichaiblog-1316355194.cos.ap-hongkong.myqcloud.com/20250119191908.png)

[[2025-01-20-CV-3]]
