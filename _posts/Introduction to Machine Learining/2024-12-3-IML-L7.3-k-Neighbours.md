---
layout: post
title: IML L7.3 k-Neighbours
author: wichai
date: 2024-12-3 14:30 +0000 
categories: [Study, Master]
tags: [DU, AI, ML]
mermaid: true
math: true
pin: false
---



# k-Neighbours

The kk-neighbours method is an instance-based learning algorithm. It remembers the training set and when a new data point is presented it looks for the closest kk samples from the training set and returns

- the average of the target values of these kk values for regression
- the class of the majority of the kk training examples. (using some procedure to break ties)



## Regularisation

The parameter kk can be used to control overfitting.

- With k=1k=1 the algorithm is likely to overfit.
- Large values of kk can lead to underfitting.



## Example

We can use the iris dataset:

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/iris_3class.png)

## k=1

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/iris_kn_1.png)

## k =3

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/iris_kn_3.png)

## k=10

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/iris_kn_10.png)

## k=20

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/iris_kn_20.png)

## Digits example

We can use the 8x8 digits picture example after applying PCA to reduce it to 2 dimensions: ![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/digits-scatter-2d.png)

## k=1

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/decision_kn_1.png)

## k=3

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/decision_kn_3.png)

## k=5

![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/presentations/k-neighbours/decision_kn_5.png)

