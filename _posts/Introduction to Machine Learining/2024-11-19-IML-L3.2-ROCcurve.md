---
layout: post
title: IML L3.2 ROC curve
author: wichai
date: 2024-11-18 14:30 +0000 
categories: [Study, Master]
tags: [DU, AI, ML]
mermaid: true
math: true
pin: false

---

# ROC curve

Let us consider the cancer data sample again

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/cancerRegions.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/cancerRegions.png)

# Quality metrics

- the performance of a binary classifier can be described by the confusion matrix

|                    | true value is positive | true value is negative |
| :----------------- | :--------------------: | :--------------------: |
| predicted positive |    true positive TP    |   false positive FP    |
| predicted negative |   false negative FN    |    True negative TN    |

- From this matrix we can define several metrics to quantify the quality of the classification.

true positive $rate=\frac{TP}{TP+FN}$

and

false positive $rate=\frac{FP}{FP+TN}$

we can see how well the prediction works by plotting the true value as a function of $z$ for each data point in the training sample:

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz.png)

- The points with$z>0$ are assigned to the$y=1$ class
  - they correspond to $p> \frac{1}{2} $
- those with $z<0$ to the $y=0$  class
  - they correspond to $p< \frac{1}{2} $

The different categories (TP, FP, TN, FN) can be visualised on this plot:

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors.png)

If we are more worried about false negative than about false positive, we can move the decision boundary to the left:

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors-m3.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors-m3.png)

Of course if means more false positives…

If we are more worried about false positive than about false negative, we can move the decision boundary to the right:

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors-p5.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/yofz_colors-p5.png)

Of course if means more false negatives…

The curve describing this trade-off is the ROC curve (Receiver Operating Characteristic). It is the collection of (FP rate, TP rate) values for all values of the decision boundary.

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=0.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=0.png)

Move the threshold to the left:

- more true positives
- more false positive

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=-5.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=-5.png)

Move the threshold to the right:

- less true positives
- less false positive

[![img](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=5.png)](https://miscada-ml-2324.notes.dmaitre.phyip3.dur.ac.uk/assets/lecture-3/roc-curve_files/ROCt=5.png)